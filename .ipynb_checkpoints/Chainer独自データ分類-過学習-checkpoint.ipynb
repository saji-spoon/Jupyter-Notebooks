{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 独自データの分類 - 多エポックにおける過学習の再現\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions\n",
    "from chainer.dataset import concat_examples\n",
    "import inspect\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "def generate_cmap(colors):\n",
    "    \"\"\"自分で定義したカラーマップを返す\"\"\"\n",
    "    values = range(len(colors))\n",
    "\n",
    "    vmax = np.ceil(np.max(values))\n",
    "    color_list = []\n",
    "    for v, c in zip(values, colors):\n",
    "        color_list.append( ( v/ vmax, c) )\n",
    "    return LinearSegmentedColormap.from_list('custom_cmap', color_list)\n",
    "\n",
    "train, test = datasets.get_mnist()\n",
    "train_iter = iterators.SerialIterator(train, batch_size=100, shuffle=True)\n",
    "test_iter = iterators.SerialIterator(train, batch_size=100, shuffle=False, repeat=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xfb225d48d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD+CAYAAAAuyi5kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWeb/B6jE60AjH0FTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xfb223cd320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ファイルから座標とクラスラベルのデータ読み込み\n",
    "file = open(\"sample1.txt\", mode='r')\n",
    "lines = file.readlines()\n",
    "\n",
    "file.close()\n",
    "\n",
    "train_pos = []\n",
    "t_label = []\n",
    "\n",
    "for line in lines:\n",
    "    vals = line.split(\",\")\n",
    "    train_pos.append([int(vals[0]),480-int(vals[1])])\n",
    "    t_label.append(int(vals[2]))\n",
    "\n",
    "#train_array\n",
    "#t_array\n",
    "\n",
    "#デフォルトでtrain_posは座標そのままなので正規化する\n",
    "sample_train = np.array(train_pos, np.float32) / np.array([640, 480], np.float32)\n",
    "sample_train_t = np.array(t_label, np.int32)\n",
    "\n",
    "import random\n",
    "#暫定的に何個かサンプリングしてテスト用データとする\n",
    "test_pos = []\n",
    "test_t_label = []\n",
    "for i in range(20) :\n",
    "    idx = random.randrange(0, sample_train.shape[0])\n",
    "    test_pos.append(train_pos[idx])\n",
    "    test_t_label.append(t_label[idx])\n",
    "    \n",
    "sample_test = np.array(test_pos, np.float32) / np.array([640, 480], np.float32)\n",
    "sample_test_t = np.array(test_t_label, np.int32)\n",
    "\n",
    "#学習用データの表示\n",
    "cm = generate_cmap(['#EE5050', '#9090FF'])\n",
    "plt.scatter(sample_train[:,0], sample_train[:,1], c=sample_train_t, cmap=cm)\n",
    "\n",
    "#コメントアウトを外してテストデータの表示\n",
    "cm_test = generate_cmap(['#50EE50', '#EE50EE'])\n",
    "#plt.scatter(sample_test[:,0], sample_test[:,1], c=sample_test_t, cmap=cm_test)\n",
    "\n",
    "#格子点サンプルの用意\n",
    "xx, yy = np.meshgrid(np.arange(0,1.0,0.01), np.arange(0,1.0,0.01))\n",
    "sample_mesh = np.array(np.c_[xx.ravel(), yy.ravel()], np.float32)\n",
    "\n",
    "from chainer.datasets import tuple_dataset\n",
    "\n",
    "#最後に、iterで取り出しやすいようTupleDatasetの形にする\n",
    "train = tuple_dataset.TupleDataset(sample_train, sample_train_t)\n",
    "test = tuple_dataset.TupleDataset(sample_test, sample_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(Chain):\n",
    "    def __init__(self, n_out):\n",
    "        super(MLP, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, 100)\n",
    "            self.l2 = L.Linear(None, 100)\n",
    "            self.l3 = L.Linear(None, 100)\n",
    "            self.l4 = L.Linear(None, 80)\n",
    "            self.l5 = L.Linear(None, 50)\n",
    "            self.l6 = L.Linear(None, 20)\n",
    "            self.l7 = L.Linear(None, n_out)\n",
    "            \n",
    "            \n",
    "    def __call__(self, x):\n",
    "        #層の結合結果に、活性化関数をかませる\n",
    "        h1 = F.tanh(self.l1(x))\n",
    "        h2 = F.tanh(self.l2(h1))\n",
    "        h3 = F.tanh(self.l3(h2))\n",
    "        h4 = F.tanh(self.l4(h3))\n",
    "        h5 = F.tanh(self.l5(h4))\n",
    "        h6 = F.tanh(self.l6(h5))\n",
    "        y = self.l7(h6)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ビギナー向けチュートリアルに沿った実装\n",
    "\n",
    "https://qiita.com/mitmul/items/eccf4e0a84cb784ba84a\n",
    "\n",
    "2 Iteratorぐらいから\n",
    "\n",
    "サンプルに対してiteratorを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'データ数'\n",
    "len(train)\n",
    "\n",
    "train_batchsize = 1\n",
    "\n",
    "train_iter = iterators.SerialIterator(train, train_batchsize)\n",
    "test_iter = iterators.SerialIterator(test, 20, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizerを定義し、モデルをセットする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ここで学習率の設定\n",
    "optimizer = optimizers.SGD(lr = 0.005)\n",
    "#上で定義したモデルのインスタンス作成 最終出力2ノード\n",
    "model = MLP(2)\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習ループ\n",
    "\n",
    "1. 入力をmodelで計算して出力yを得る\n",
    "2. yからloss値を計算する　今回はsoftmax_cross_entropyを使う\n",
    "3. loss値に対する各パラメータの勾配を計算する\n",
    "4. optimizerでupdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now at  1\n",
      "loss: variable(0.9766220450401306)\n",
      "accuracy: variable(0.3499999940395355)\n",
      "Now at  2\n",
      "loss: variable(0.6951461434364319)\n",
      "accuracy: variable(0.5)\n",
      "Now at  3\n",
      "loss: variable(0.5879486203193665)\n",
      "accuracy: variable(0.75)\n",
      "Now at  4\n",
      "loss: variable(0.797805905342102)\n",
      "accuracy: variable(0.3499999940395355)\n",
      "Now at  5\n",
      "loss: variable(0.7089099884033203)\n",
      "accuracy: variable(0.5)\n",
      "Now at  6\n",
      "loss: variable(0.6826739311218262)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  7\n",
      "loss: variable(0.800165593624115)\n",
      "accuracy: variable(0.44999998807907104)\n",
      "Now at  8\n",
      "loss: variable(0.7965994477272034)\n",
      "accuracy: variable(0.5)\n",
      "Now at  9\n",
      "loss: variable(0.6121150851249695)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  10\n",
      "loss: variable(0.9097839593887329)\n",
      "accuracy: variable(0.5)\n",
      "Now at  11\n",
      "loss: variable(0.668648898601532)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  12\n",
      "loss: variable(0.47953787446022034)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  13\n",
      "loss: variable(0.5071517825126648)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  14\n",
      "loss: variable(0.5813519358634949)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  15\n",
      "loss: variable(0.6262180209159851)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  16\n",
      "loss: variable(0.7648030519485474)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  17\n",
      "loss: variable(0.5772403478622437)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  18\n",
      "loss: variable(0.6055313944816589)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  19\n",
      "loss: variable(0.640146791934967)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  20\n",
      "loss: variable(0.6357333064079285)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  21\n",
      "loss: variable(0.5934783816337585)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  22\n",
      "loss: variable(0.7852620482444763)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  23\n",
      "loss: variable(0.6005733013153076)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  24\n",
      "loss: variable(0.5477901697158813)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  25\n",
      "loss: variable(0.6375719308853149)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  26\n",
      "loss: variable(0.6717738509178162)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  27\n",
      "loss: variable(0.6573200225830078)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  28\n",
      "loss: variable(0.8605619668960571)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  29\n",
      "loss: variable(0.5585280656814575)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  30\n",
      "loss: variable(0.804276168346405)\n",
      "accuracy: variable(0.5)\n",
      "Now at  31\n",
      "loss: variable(0.4869700074195862)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  32\n",
      "loss: variable(0.522381067276001)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  33\n",
      "loss: variable(0.5001910924911499)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  34\n",
      "loss: variable(0.6627143025398254)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  35\n",
      "loss: variable(0.46133193373680115)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  36\n",
      "loss: variable(0.45836010575294495)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  37\n",
      "loss: variable(0.5571584701538086)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  38\n",
      "loss: variable(0.5770077109336853)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  39\n",
      "loss: variable(0.8485962748527527)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  40\n",
      "loss: variable(0.49501362442970276)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  41\n",
      "loss: variable(0.4915545880794525)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  42\n",
      "loss: variable(0.5917985439300537)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  43\n",
      "loss: variable(0.6196542978286743)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  44\n",
      "loss: variable(0.5495266318321228)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  45\n",
      "loss: variable(0.5309779047966003)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  46\n",
      "loss: variable(0.5807134509086609)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  47\n",
      "loss: variable(0.6959654092788696)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  48\n",
      "loss: variable(0.7463640570640564)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  49\n",
      "loss: variable(0.6307533383369446)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  50\n",
      "loss: variable(0.5142092108726501)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  51\n",
      "loss: variable(0.4813162386417389)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  52\n",
      "loss: variable(0.6454363465309143)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  53\n",
      "loss: variable(0.49043938517570496)\n",
      "accuracy: variable(0.75)\n",
      "Now at  54\n",
      "loss: variable(0.48535582423210144)\n",
      "accuracy: variable(0.75)\n",
      "Now at  55\n",
      "loss: variable(0.6080369353294373)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  56\n",
      "loss: variable(0.5643898248672485)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  57\n",
      "loss: variable(0.6679200530052185)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  58\n",
      "loss: variable(0.4997376501560211)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  59\n",
      "loss: variable(0.6357378363609314)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  60\n",
      "loss: variable(0.5040025115013123)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  61\n",
      "loss: variable(0.48804059624671936)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  62\n",
      "loss: variable(0.8129383325576782)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  63\n",
      "loss: variable(0.5764080882072449)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  64\n",
      "loss: variable(0.5194432139396667)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  65\n",
      "loss: variable(0.5512906908988953)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  66\n",
      "loss: variable(0.6013227105140686)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  67\n",
      "loss: variable(0.6803061366081238)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  68\n",
      "loss: variable(0.5305888652801514)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  69\n",
      "loss: variable(0.5684090852737427)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  70\n",
      "loss: variable(0.6112726926803589)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  71\n",
      "loss: variable(0.62506502866745)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  72\n",
      "loss: variable(0.5765174031257629)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  73\n",
      "loss: variable(0.6887671947479248)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  74\n",
      "loss: variable(0.4689273536205292)\n",
      "accuracy: variable(0.75)\n",
      "Now at  75\n",
      "loss: variable(0.5374416708946228)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  76\n",
      "loss: variable(0.6721778512001038)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  77\n",
      "loss: variable(0.5856298208236694)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  78\n",
      "loss: variable(0.5376980900764465)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  79\n",
      "loss: variable(0.5842894911766052)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  80\n",
      "loss: variable(0.6941289901733398)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  81\n",
      "loss: variable(0.5277509093284607)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  82\n",
      "loss: variable(0.5456575751304626)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  83\n",
      "loss: variable(0.588071346282959)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  84\n",
      "loss: variable(0.5398778319358826)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  85\n",
      "loss: variable(0.5989677309989929)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  86\n",
      "loss: variable(0.5860564112663269)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  87\n",
      "loss: variable(0.6209871172904968)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  88\n",
      "loss: variable(0.5095553994178772)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  89\n",
      "loss: variable(0.49263277649879456)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  90\n",
      "loss: variable(0.4672771990299225)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  91\n",
      "loss: variable(0.6088733077049255)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  92\n",
      "loss: variable(0.6614634990692139)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  93\n",
      "loss: variable(0.5177777409553528)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  94\n",
      "loss: variable(0.4918045699596405)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  95\n",
      "loss: variable(0.5279879570007324)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  96\n",
      "loss: variable(0.684654176235199)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  97\n",
      "loss: variable(0.4729267656803131)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  98\n",
      "loss: variable(0.4782860279083252)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  99\n",
      "loss: variable(0.574110209941864)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  100\n",
      "loss: variable(0.6020318865776062)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  101\n",
      "loss: variable(0.5042774677276611)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  102\n",
      "loss: variable(0.5073665976524353)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  103\n",
      "loss: variable(0.5798670053482056)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  104\n",
      "loss: variable(0.6106188297271729)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  105\n",
      "loss: variable(0.5411774516105652)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  106\n",
      "loss: variable(0.7172217965126038)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  107\n",
      "loss: variable(0.5400428175926208)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  108\n",
      "loss: variable(0.5425066947937012)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  109\n",
      "loss: variable(0.5419811606407166)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  110\n",
      "loss: variable(0.5748228430747986)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  111\n",
      "loss: variable(0.5943019986152649)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  112\n",
      "loss: variable(0.524048924446106)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  113\n",
      "loss: variable(0.5240380167961121)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  114\n",
      "loss: variable(0.6328303217887878)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  115\n",
      "loss: variable(0.4985577166080475)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  116\n",
      "loss: variable(0.6243781447410583)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  117\n",
      "loss: variable(0.5060082077980042)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  118\n",
      "loss: variable(0.47407323122024536)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  119\n",
      "loss: variable(0.4788268506526947)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  120\n",
      "loss: variable(0.5693339705467224)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  121\n",
      "loss: variable(0.5110020041465759)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  122\n",
      "loss: variable(0.5533651113510132)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  123\n",
      "loss: variable(0.47589799761772156)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  124\n",
      "loss: variable(0.4764164388179779)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  125\n",
      "loss: variable(0.5014840960502625)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  126\n",
      "loss: variable(0.6288323998451233)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  127\n",
      "loss: variable(0.5459136366844177)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  128\n",
      "loss: variable(0.5947861075401306)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  129\n",
      "loss: variable(0.5733365416526794)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  130\n",
      "loss: variable(0.48819610476493835)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  131\n",
      "loss: variable(0.5733487010002136)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  132\n",
      "loss: variable(0.555438220500946)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  133\n",
      "loss: variable(0.5357384085655212)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  134\n",
      "loss: variable(0.6114833950996399)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  135\n",
      "loss: variable(0.5949631929397583)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  136\n",
      "loss: variable(0.5130283236503601)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  137\n",
      "loss: variable(0.49904051423072815)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  138\n",
      "loss: variable(0.5238999724388123)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  139\n",
      "loss: variable(0.4881586730480194)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  140\n",
      "loss: variable(0.5096572637557983)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  141\n",
      "loss: variable(0.5401267409324646)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  142\n",
      "loss: variable(0.5152647495269775)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  143\n",
      "loss: variable(0.5607147812843323)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  144\n",
      "loss: variable(0.49577903747558594)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  145\n",
      "loss: variable(0.49763065576553345)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  146\n",
      "loss: variable(0.45223909616470337)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  147\n",
      "loss: variable(0.6328525543212891)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  148\n",
      "loss: variable(0.5597929358482361)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  149\n",
      "loss: variable(0.5040168762207031)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  150\n",
      "loss: variable(0.5829081535339355)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  151\n",
      "loss: variable(0.5225014090538025)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  152\n",
      "loss: variable(0.5086225867271423)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  153\n",
      "loss: variable(0.5508982539176941)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  154\n",
      "loss: variable(0.5913309454917908)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  155\n",
      "loss: variable(0.520589292049408)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  156\n",
      "loss: variable(0.5674771666526794)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  157\n",
      "loss: variable(0.5122267603874207)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  158\n",
      "loss: variable(0.5766562819480896)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  159\n",
      "loss: variable(0.5730642080307007)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  160\n",
      "loss: variable(0.45054760575294495)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  161\n",
      "loss: variable(0.6498645544052124)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  162\n",
      "loss: variable(0.5417719483375549)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  163\n",
      "loss: variable(0.5304004549980164)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  164\n",
      "loss: variable(0.451585978269577)\n",
      "accuracy: variable(0.75)\n",
      "Now at  165\n",
      "loss: variable(0.5170301795005798)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  166\n",
      "loss: variable(0.4634450376033783)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  167\n",
      "loss: variable(0.5517520308494568)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  168\n",
      "loss: variable(0.5149163007736206)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  169\n",
      "loss: variable(0.5670685172080994)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  170\n",
      "loss: variable(0.5285431742668152)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  171\n",
      "loss: variable(0.5078244209289551)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  172\n",
      "loss: variable(0.5068883895874023)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  173\n",
      "loss: variable(0.4717676639556885)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  174\n",
      "loss: variable(0.4998403489589691)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  175\n",
      "loss: variable(0.44799086451530457)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  176\n",
      "loss: variable(0.45524102449417114)\n",
      "accuracy: variable(0.75)\n",
      "Now at  177\n",
      "loss: variable(0.5934590697288513)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  178\n",
      "loss: variable(0.524013876914978)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  179\n",
      "loss: variable(0.5757367014884949)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  180\n",
      "loss: variable(0.47233128547668457)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  181\n",
      "loss: variable(0.5213271975517273)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  182\n",
      "loss: variable(0.5077853202819824)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  183\n",
      "loss: variable(0.4727228283882141)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  184\n",
      "loss: variable(0.48139724135398865)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  185\n",
      "loss: variable(0.562259316444397)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  186\n",
      "loss: variable(0.5159314274787903)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  187\n",
      "loss: variable(0.49166417121887207)\n",
      "accuracy: variable(0.75)\n",
      "Now at  188\n",
      "loss: variable(0.4812057912349701)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  189\n",
      "loss: variable(0.5207510590553284)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  190\n",
      "loss: variable(0.510828971862793)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  191\n",
      "loss: variable(0.47093406319618225)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  192\n",
      "loss: variable(0.4772883355617523)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  193\n",
      "loss: variable(0.44523611664772034)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  194\n",
      "loss: variable(0.44522103667259216)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  195\n",
      "loss: variable(0.6682289838790894)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  196\n",
      "loss: variable(0.43676242232322693)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  197\n",
      "loss: variable(0.5592132806777954)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  198\n",
      "loss: variable(0.48561134934425354)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  199\n",
      "loss: variable(0.4559929370880127)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  200\n",
      "loss: variable(0.4182046055793762)\n",
      "accuracy: variable(0.75)\n",
      "Now at  201\n",
      "loss: variable(0.5831093192100525)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  202\n",
      "loss: variable(0.467899888753891)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  203\n",
      "loss: variable(0.54824298620224)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  204\n",
      "loss: variable(0.4320872724056244)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  205\n",
      "loss: variable(0.4853999614715576)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  206\n",
      "loss: variable(0.7235475182533264)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  207\n",
      "loss: variable(0.5153323411941528)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  208\n",
      "loss: variable(0.41127893328666687)\n",
      "accuracy: variable(0.75)\n",
      "Now at  209\n",
      "loss: variable(0.5472926497459412)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  210\n",
      "loss: variable(0.4200441539287567)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  211\n",
      "loss: variable(0.5260226130485535)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  212\n",
      "loss: variable(0.4235103130340576)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  213\n",
      "loss: variable(0.4533795416355133)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  214\n",
      "loss: variable(0.4805924594402313)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  215\n",
      "loss: variable(0.5606836676597595)\n",
      "accuracy: variable(0.75)\n",
      "Now at  216\n",
      "loss: variable(0.46749192476272583)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  217\n",
      "loss: variable(0.46137604117393494)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  218\n",
      "loss: variable(0.4133525490760803)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  219\n",
      "loss: variable(0.5779269337654114)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  220\n",
      "loss: variable(0.41064366698265076)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  221\n",
      "loss: variable(0.819645881652832)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  222\n",
      "loss: variable(0.4751605987548828)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  223\n",
      "loss: variable(0.4189938008785248)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  224\n",
      "loss: variable(0.4335040748119354)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  225\n",
      "loss: variable(0.37129631638526917)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  226\n",
      "loss: variable(0.45247870683670044)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  227\n",
      "loss: variable(0.36493057012557983)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  228\n",
      "loss: variable(0.4345432221889496)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  229\n",
      "loss: variable(0.5668433904647827)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  230\n",
      "loss: variable(0.34624168276786804)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  231\n",
      "loss: variable(0.35447707772254944)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  232\n",
      "loss: variable(0.41559037566185)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  233\n",
      "loss: variable(0.4319028854370117)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  234\n",
      "loss: variable(0.3882220685482025)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  235\n",
      "loss: variable(0.37479740381240845)\n",
      "accuracy: variable(0.75)\n",
      "Now at  236\n",
      "loss: variable(0.4206652343273163)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  237\n",
      "loss: variable(0.40205883979797363)\n",
      "accuracy: variable(0.75)\n",
      "Now at  238\n",
      "loss: variable(0.35420921444892883)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  239\n",
      "loss: variable(0.5320855975151062)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  240\n",
      "loss: variable(0.35969725251197815)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  241\n",
      "loss: variable(0.3671092391014099)\n",
      "accuracy: variable(0.75)\n",
      "Now at  242\n",
      "loss: variable(0.48485302925109863)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  243\n",
      "loss: variable(0.44179782271385193)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  244\n",
      "loss: variable(0.4874415397644043)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  245\n",
      "loss: variable(0.3580622375011444)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  246\n",
      "loss: variable(0.34625300765037537)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  247\n",
      "loss: variable(0.3772696554660797)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  248\n",
      "loss: variable(0.3515591621398926)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  249\n",
      "loss: variable(0.380509614944458)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  250\n",
      "loss: variable(0.5795737504959106)\n",
      "accuracy: variable(0.550000011920929)\n",
      "Now at  251\n",
      "loss: variable(0.3463066816329956)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  252\n",
      "loss: variable(0.36866655945777893)\n",
      "accuracy: variable(0.75)\n",
      "Now at  253\n",
      "loss: variable(0.3376730680465698)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  254\n",
      "loss: variable(0.42203837633132935)\n",
      "accuracy: variable(0.75)\n",
      "Now at  255\n",
      "loss: variable(0.3727244436740875)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  256\n",
      "loss: variable(0.3193383812904358)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  257\n",
      "loss: variable(0.3778899013996124)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  258\n",
      "loss: variable(0.36528724431991577)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  259\n",
      "loss: variable(0.29342174530029297)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  260\n",
      "loss: variable(0.286201149225235)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  261\n",
      "loss: variable(0.38485953211784363)\n",
      "accuracy: variable(0.75)\n",
      "Now at  262\n",
      "loss: variable(0.2735407054424286)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  263\n",
      "loss: variable(0.3208453357219696)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  264\n",
      "loss: variable(0.4020465910434723)\n",
      "accuracy: variable(0.75)\n",
      "Now at  265\n",
      "loss: variable(0.2644510269165039)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  266\n",
      "loss: variable(0.31534266471862793)\n",
      "accuracy: variable(0.75)\n",
      "Now at  267\n",
      "loss: variable(0.46624866127967834)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  268\n",
      "loss: variable(0.49125489592552185)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  269\n",
      "loss: variable(0.37068697810173035)\n",
      "accuracy: variable(0.75)\n",
      "Now at  270\n",
      "loss: variable(0.33541613817214966)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  271\n",
      "loss: variable(0.359454870223999)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  272\n",
      "loss: variable(0.44940003752708435)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  273\n",
      "loss: variable(0.3723699748516083)\n",
      "accuracy: variable(0.75)\n",
      "Now at  274\n",
      "loss: variable(0.4295608699321747)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  275\n",
      "loss: variable(0.394937127828598)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  276\n",
      "loss: variable(0.3522355258464813)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  277\n",
      "loss: variable(0.37958434224128723)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  278\n",
      "loss: variable(0.4027080237865448)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  279\n",
      "loss: variable(0.44546183943748474)\n",
      "accuracy: variable(0.75)\n",
      "Now at  280\n",
      "loss: variable(0.30020666122436523)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  281\n",
      "loss: variable(0.41138625144958496)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  282\n",
      "loss: variable(0.2943292260169983)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  283\n",
      "loss: variable(0.3584844172000885)\n",
      "accuracy: variable(0.75)\n",
      "Now at  284\n",
      "loss: variable(0.39421430230140686)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  285\n",
      "loss: variable(0.29157838225364685)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  286\n",
      "loss: variable(0.2967322766780853)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  287\n",
      "loss: variable(0.30640512704849243)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  288\n",
      "loss: variable(0.3753769099712372)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  289\n",
      "loss: variable(0.23294305801391602)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  290\n",
      "loss: variable(0.2896392345428467)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  291\n",
      "loss: variable(0.3497837483882904)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  292\n",
      "loss: variable(0.264644056558609)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  293\n",
      "loss: variable(0.3854253590106964)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  294\n",
      "loss: variable(0.5573650598526001)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  295\n",
      "loss: variable(0.37365904450416565)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  296\n",
      "loss: variable(0.3380270302295685)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  297\n",
      "loss: variable(0.2606963813304901)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  298\n",
      "loss: variable(0.4358905851840973)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  299\n",
      "loss: variable(0.48456206917762756)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  300\n",
      "loss: variable(0.23194098472595215)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  301\n",
      "loss: variable(0.2599858343601227)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  302\n",
      "loss: variable(0.47464561462402344)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  303\n",
      "loss: variable(0.2730013430118561)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  304\n",
      "loss: variable(0.35879501700401306)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  305\n",
      "loss: variable(0.2415604591369629)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  306\n",
      "loss: variable(0.3044094145298004)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  307\n",
      "loss: variable(0.34416958689689636)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  308\n",
      "loss: variable(0.24889107048511505)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  309\n",
      "loss: variable(0.446639746427536)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  310\n",
      "loss: variable(0.4039194583892822)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  311\n",
      "loss: variable(0.25167733430862427)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  312\n",
      "loss: variable(0.437338262796402)\n",
      "accuracy: variable(0.75)\n",
      "Now at  313\n",
      "loss: variable(0.5047673583030701)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  314\n",
      "loss: variable(0.34918710589408875)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  315\n",
      "loss: variable(0.21999052166938782)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  316\n",
      "loss: variable(0.5072380900382996)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  317\n",
      "loss: variable(0.5144187808036804)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  318\n",
      "loss: variable(0.2428913563489914)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  319\n",
      "loss: variable(0.2122640162706375)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  320\n",
      "loss: variable(0.2833898663520813)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  321\n",
      "loss: variable(0.21286535263061523)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  322\n",
      "loss: variable(0.3782661557197571)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  323\n",
      "loss: variable(0.4320800006389618)\n",
      "accuracy: variable(0.75)\n",
      "Now at  324\n",
      "loss: variable(0.31083253026008606)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  325\n",
      "loss: variable(0.3243701756000519)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  326\n",
      "loss: variable(0.5278121829032898)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  327\n",
      "loss: variable(0.2588808238506317)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  328\n",
      "loss: variable(0.21606050431728363)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  329\n",
      "loss: variable(0.2951575815677643)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  330\n",
      "loss: variable(0.34221628308296204)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  331\n",
      "loss: variable(0.3979363441467285)\n",
      "accuracy: variable(0.75)\n",
      "Now at  332\n",
      "loss: variable(0.32799097895622253)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  333\n",
      "loss: variable(0.24774964153766632)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  334\n",
      "loss: variable(0.309772789478302)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  335\n",
      "loss: variable(0.2313273400068283)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  336\n",
      "loss: variable(0.3426940441131592)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  337\n",
      "loss: variable(0.41342535614967346)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  338\n",
      "loss: variable(0.20556767284870148)\n",
      "accuracy: variable(1.0)\n",
      "Now at  339\n",
      "loss: variable(0.20762577652931213)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  340\n",
      "loss: variable(0.3385768234729767)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  341\n",
      "loss: variable(0.38991519808769226)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  342\n",
      "loss: variable(0.26073458790779114)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  343\n",
      "loss: variable(0.2642901837825775)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  344\n",
      "loss: variable(0.24895325303077698)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  345\n",
      "loss: variable(0.2554604113101959)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  346\n",
      "loss: variable(0.3045341372489929)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  347\n",
      "loss: variable(0.28127869963645935)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  348\n",
      "loss: variable(0.23307791352272034)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  349\n",
      "loss: variable(0.2552121877670288)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  350\n",
      "loss: variable(0.4660470187664032)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  351\n",
      "loss: variable(0.45367953181266785)\n",
      "accuracy: variable(0.75)\n",
      "Now at  352\n",
      "loss: variable(0.3089003264904022)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  353\n",
      "loss: variable(0.6310257315635681)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  354\n",
      "loss: variable(0.2309959977865219)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  355\n",
      "loss: variable(0.28418445587158203)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  356\n",
      "loss: variable(0.32368192076683044)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  357\n",
      "loss: variable(0.2025894671678543)\n",
      "accuracy: variable(1.0)\n",
      "Now at  358\n",
      "loss: variable(0.27166780829429626)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  359\n",
      "loss: variable(0.2436358481645584)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  360\n",
      "loss: variable(0.2265137881040573)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  361\n",
      "loss: variable(0.284003347158432)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  362\n",
      "loss: variable(0.21282339096069336)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  363\n",
      "loss: variable(0.7307413220405579)\n",
      "accuracy: variable(0.6499999761581421)\n",
      "Now at  364\n",
      "loss: variable(0.3601936995983124)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  365\n",
      "loss: variable(0.27123838663101196)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  366\n",
      "loss: variable(0.20681457221508026)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  367\n",
      "loss: variable(0.21588650345802307)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  368\n",
      "loss: variable(0.3217833638191223)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  369\n",
      "loss: variable(0.20583198964595795)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  370\n",
      "loss: variable(0.25429195165634155)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  371\n",
      "loss: variable(0.21664412319660187)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  372\n",
      "loss: variable(0.4530646800994873)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  373\n",
      "loss: variable(0.3973813056945801)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  374\n",
      "loss: variable(0.2301398068666458)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  375\n",
      "loss: variable(0.25005027651786804)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  376\n",
      "loss: variable(0.27807945013046265)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  377\n",
      "loss: variable(0.3052975535392761)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  378\n",
      "loss: variable(0.4145088195800781)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  379\n",
      "loss: variable(0.2071462869644165)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  380\n",
      "loss: variable(0.3637232482433319)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  381\n",
      "loss: variable(0.22562454640865326)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  382\n",
      "loss: variable(0.6110163331031799)\n",
      "accuracy: variable(0.6000000238418579)\n",
      "Now at  383\n",
      "loss: variable(0.15763531625270844)\n",
      "accuracy: variable(1.0)\n",
      "Now at  384\n",
      "loss: variable(0.37451407313346863)\n",
      "accuracy: variable(0.75)\n",
      "Now at  385\n",
      "loss: variable(0.19025181233882904)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  386\n",
      "loss: variable(0.19146829843521118)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  387\n",
      "loss: variable(0.22526021301746368)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  388\n",
      "loss: variable(0.22446881234645844)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  389\n",
      "loss: variable(0.19696246087551117)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  390\n",
      "loss: variable(0.1924997717142105)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  391\n",
      "loss: variable(0.3040076792240143)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  392\n",
      "loss: variable(0.2818564474582672)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  393\n",
      "loss: variable(0.4435158371925354)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  394\n",
      "loss: variable(0.36010563373565674)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  395\n",
      "loss: variable(0.28562650084495544)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  396\n",
      "loss: variable(0.3078184127807617)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  397\n",
      "loss: variable(0.21330685913562775)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  398\n",
      "loss: variable(0.18688060343265533)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  399\n",
      "loss: variable(0.25484296679496765)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  400\n",
      "loss: variable(0.4880642592906952)\n",
      "accuracy: variable(0.75)\n",
      "Now at  401\n",
      "loss: variable(0.20070095360279083)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  402\n",
      "loss: variable(0.280786395072937)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  403\n",
      "loss: variable(0.154619038105011)\n",
      "accuracy: variable(1.0)\n",
      "Now at  404\n",
      "loss: variable(0.48921218514442444)\n",
      "accuracy: variable(0.75)\n",
      "Now at  405\n",
      "loss: variable(0.1898375004529953)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  406\n",
      "loss: variable(0.17576754093170166)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  407\n",
      "loss: variable(0.2337137758731842)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  408\n",
      "loss: variable(0.21937032043933868)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  409\n",
      "loss: variable(0.2665344476699829)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  410\n",
      "loss: variable(0.20461440086364746)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  411\n",
      "loss: variable(0.1757737249135971)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  412\n",
      "loss: variable(0.16211800277233124)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  413\n",
      "loss: variable(0.3693009912967682)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  414\n",
      "loss: variable(0.22934822738170624)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  415\n",
      "loss: variable(0.6347543001174927)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  416\n",
      "loss: variable(0.18549679219722748)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  417\n",
      "loss: variable(0.27617359161376953)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  418\n",
      "loss: variable(0.26743564009666443)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  419\n",
      "loss: variable(0.18017853796482086)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  420\n",
      "loss: variable(0.1514638513326645)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  421\n",
      "loss: variable(0.2060360461473465)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  422\n",
      "loss: variable(0.26599016785621643)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  423\n",
      "loss: variable(0.254848450422287)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  424\n",
      "loss: variable(0.2510911524295807)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  425\n",
      "loss: variable(0.17304396629333496)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  426\n",
      "loss: variable(0.1503044217824936)\n",
      "accuracy: variable(1.0)\n",
      "Now at  427\n",
      "loss: variable(0.3706192672252655)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  428\n",
      "loss: variable(0.4724958539009094)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  429\n",
      "loss: variable(0.20509114861488342)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  430\n",
      "loss: variable(0.16858510673046112)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  431\n",
      "loss: variable(0.19525966048240662)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  432\n",
      "loss: variable(0.16601639986038208)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  433\n",
      "loss: variable(0.14519453048706055)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  434\n",
      "loss: variable(0.20509116351604462)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  435\n",
      "loss: variable(0.2917191982269287)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  436\n",
      "loss: variable(0.1863202303647995)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  437\n",
      "loss: variable(0.14627978205680847)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  438\n",
      "loss: variable(0.14620280265808105)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  439\n",
      "loss: variable(0.20888714492321014)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  440\n",
      "loss: variable(0.41152191162109375)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  441\n",
      "loss: variable(0.1520419865846634)\n",
      "accuracy: variable(1.0)\n",
      "Now at  442\n",
      "loss: variable(0.1858675479888916)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  443\n",
      "loss: variable(0.11240698397159576)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  444\n",
      "loss: variable(0.11085481941699982)\n",
      "accuracy: variable(1.0)\n",
      "Now at  445\n",
      "loss: variable(0.17289678752422333)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  446\n",
      "loss: variable(0.1892799735069275)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  447\n",
      "loss: variable(0.12579616904258728)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  448\n",
      "loss: variable(0.23258423805236816)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  449\n",
      "loss: variable(0.24656720459461212)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  450\n",
      "loss: variable(0.16477856040000916)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  451\n",
      "loss: variable(0.20633523166179657)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  452\n",
      "loss: variable(0.18363334238529205)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  453\n",
      "loss: variable(0.1569746732711792)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  454\n",
      "loss: variable(0.17517156898975372)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  455\n",
      "loss: variable(0.18147602677345276)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  456\n",
      "loss: variable(0.18175093829631805)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  457\n",
      "loss: variable(0.28758516907691956)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  458\n",
      "loss: variable(0.27595967054367065)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  459\n",
      "loss: variable(0.16364388167858124)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  460\n",
      "loss: variable(0.38611534237861633)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  461\n",
      "loss: variable(0.16092020273208618)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  462\n",
      "loss: variable(0.20505276322364807)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  463\n",
      "loss: variable(0.12125344574451447)\n",
      "accuracy: variable(1.0)\n",
      "Now at  464\n",
      "loss: variable(0.17506343126296997)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  465\n",
      "loss: variable(0.4744384288787842)\n",
      "accuracy: variable(0.75)\n",
      "Now at  466\n",
      "loss: variable(0.17049460113048553)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  467\n",
      "loss: variable(0.18826059997081757)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  468\n",
      "loss: variable(0.14398832619190216)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  469\n",
      "loss: variable(0.30110451579093933)\n",
      "accuracy: variable(0.800000011920929)\n",
      "Now at  470\n",
      "loss: variable(0.1526549905538559)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  471\n",
      "loss: variable(0.2020070105791092)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  472\n",
      "loss: variable(0.2071886509656906)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  473\n",
      "loss: variable(0.15465496480464935)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  474\n",
      "loss: variable(0.10163692384958267)\n",
      "accuracy: variable(1.0)\n",
      "Now at  475\n",
      "loss: variable(0.11184519529342651)\n",
      "accuracy: variable(1.0)\n",
      "Now at  476\n",
      "loss: variable(0.14329247176647186)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  477\n",
      "loss: variable(0.3994535505771637)\n",
      "accuracy: variable(0.75)\n",
      "Now at  478\n",
      "loss: variable(0.18616507947444916)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  479\n",
      "loss: variable(0.19342251121997833)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  480\n",
      "loss: variable(0.20868101716041565)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  481\n",
      "loss: variable(0.1812427043914795)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  482\n",
      "loss: variable(0.25010544061660767)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  483\n",
      "loss: variable(0.1909763067960739)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  484\n",
      "loss: variable(0.15258167684078217)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  485\n",
      "loss: variable(0.6010579466819763)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  486\n",
      "loss: variable(0.1794908344745636)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  487\n",
      "loss: variable(0.13684134185314178)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  488\n",
      "loss: variable(0.14390403032302856)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  489\n",
      "loss: variable(0.24370501935482025)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  490\n",
      "loss: variable(0.13821972906589508)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  491\n",
      "loss: variable(0.1465623676776886)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  492\n",
      "loss: variable(0.2534324824810028)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  493\n",
      "loss: variable(0.17339031398296356)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  494\n",
      "loss: variable(0.29292383790016174)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  495\n",
      "loss: variable(0.24448025226593018)\n",
      "accuracy: variable(0.8500000238418579)\n",
      "Now at  496\n",
      "loss: variable(0.578057050704956)\n",
      "accuracy: variable(0.699999988079071)\n",
      "Now at  497\n",
      "loss: variable(0.14252673089504242)\n",
      "accuracy: variable(0.949999988079071)\n",
      "Now at  498\n",
      "loss: variable(0.19446082413196564)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  499\n",
      "loss: variable(0.2669311761856079)\n",
      "accuracy: variable(0.8999999761581421)\n",
      "Now at  500\n",
      "loss: variable(0.1325361579656601)\n",
      "accuracy: variable(0.8999999761581421)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_epoch = 500\n",
    "\n",
    "while train_iter.epoch < max_epoch:\n",
    "    #バッチを1つ取り出す\n",
    "    train_batch = train_iter.next()\n",
    "    #学習用データとラベルを一緒にとってしまっているのでバラす\n",
    "    x, t = concat_examples(train_batch)\n",
    "    #出力を得る\n",
    "    y = model(x)\n",
    "    #lossを計算\n",
    "    loss = F.softmax_cross_entropy(y, t)    \n",
    "    #新しく勾配計算を始めるごとにモデルの勾配を初期化\n",
    "    model.cleargrads()\n",
    "    #lossに対して各パラメータの勾配を計算\n",
    "    loss.backward()\n",
    "    #勾配計算済みなので引数なしでupdateを呼び出す\n",
    "    optimizer.update() \n",
    "    \n",
    "    #テストデータに対してモデルを適用し,accuracyとlossを算出\n",
    "    #モデルの性能が上がっていることを確かめる\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    if train_iter.is_new_epoch:\n",
    "        while True:\n",
    "            test_batch = test_iter.next()\n",
    "            x, t = concat_examples(test_batch)\n",
    "            y = model(x)\n",
    "            loss = F.softmax_cross_entropy(y, t)    \n",
    "            accuracy = F.accuracy(y, t)\n",
    "            print(\"Now at \", train_iter.epoch)\n",
    "            print(\"loss:\", loss)\n",
    "            print(\"accuracy:\", accuracy)\n",
    "            \n",
    "            if test_iter.is_new_epoch:\n",
    "                test_iter.reset()\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作成モデルを格子点に適用して可視化\n",
    "\n",
    "作成したデータ点-クラスラベルを学習したモデルを用いて\n",
    "\n",
    "各格子点をどのようにクラス分けするか見る\n",
    "\n",
    "これによって分類境界を見ることができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xfb1ed1fef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xfb1ed299b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD6CAYAAAC1W2xyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY0zEWGE3xpiIscJujDERY4XdGGMi5v8wZoYyFjVzUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xfb22888208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = model(sample_mesh)\n",
    "\n",
    "predict_label = F.argmax(y, axis=1).data\n",
    "\n",
    "cm = generate_cmap(['#000000', '#FFFFFF'])\n",
    "templ = plt.scatter(sample_mesh[:,0], sample_mesh[:,1], c=predict_label, cmap=cm)\n",
    "\n",
    "cm = generate_cmap(['#EE5050', '#9090FF'])\n",
    "templ = plt.scatter(sample_train[:,0], sample_train[:,1], c=sample_train_t, cmap=cm)\n",
    "\n",
    "#テスト用データの表示\n",
    "#plt.scatter(sample_test[:,0], sample_test[:,1], c=sample_test_t, cmap=cm_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "赤 = 学習用データクラス0\n",
    "\n",
    "青 = 学習用データクラス1\n",
    "\n",
    "（緑と桃はテスト用データ…accuracyとlossの途中経過レポートに使われている）\n",
    "\n",
    "黒 = 学習したモデルが判定したクラス0\n",
    "\n",
    "白 = 学習したモデルが判定したクラス1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 知見など\n",
    "\n",
    "今回の用にサンプル数が少ないと、バッチサイズを大きくしすぎるとコーナーケースのlossが潰れる？（図右端のクラス1（青）など）\n",
    "\n",
    "やはり学習率は重要っぽい\n",
    "\n",
    "他中間ノード数などで調節可能\n",
    "\n",
    "学習率=0.01～0.005で、学習数（＝データ数×エポック数）が多くないと全然分類できない模様？\n",
    "\n",
    "80サンプルで200epoch\n",
    "\n",
    "200サンプルで40epochぐらいで見た目よい結果\n",
    "\n",
    "\n",
    "活性化関数はtanhがよいのかも？\n",
    "\n",
    "https://qiita.com/miyamotok0105/items/3435930cc04650bce54d\n",
    "\n",
    "今後の指針：\n",
    "\n",
    "層の数はそんなになくてもいいのでは。\n",
    "\n",
    "過学習を正則化項で抑えられるかどうか"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
